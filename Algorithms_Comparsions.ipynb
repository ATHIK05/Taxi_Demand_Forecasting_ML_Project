{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Taxi Demand Forecasting: Algorithm Comparisons (2025 Data)\n",
        "\n",
        "**Workflow:**\n",
        "1. Synthesize new taxi demand and weather datasets for Jan-May 2025 (shifting only time columns, preserving all other data).\n",
        "2. Preprocess the new data using the same logic as previous notebooks.\n",
        "3. Train and compare 7 modern algorithms (including boosting and balancing techniques) for demand forecasting.\n",
        "4. Evaluate and compare model performance, aiming for 90-93% accuracy without overfitting.\n",
        "\n",
        "> **Note:** This notebook does not modify or overwrite any existing notebooks or data files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created data/2025-04_1H_zone.csv\n",
            "Created data/2025-05_1H_zone.csv\n",
            "Created data/2025-06_1H_zone.csv\n",
            "Created data/2025-07_1H_zone.csv\n",
            "Created data/2025-08_1H_zone.csv\n",
            "Created data/weather_2025.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import shutil\n",
        "\n",
        "# --- Parameters ---\n",
        "ORIG_ZONE_FILES = [\n",
        "    'data/2017-01_1H_zone.csv',\n",
        "    'data/2017-02_1H_zone.csv',\n",
        "    'data/2017-03_1H_zone.csv',\n",
        "    'data/2017-04_1H_zone.csv',\n",
        "    'data/2017-05_1H_zone.csv',\n",
        "]\n",
        "ORIG_WEATHER_FILE = 'data/weather.csv'\n",
        "\n",
        "# Set the target year and months (last 5 months ending previous month)\n",
        "today = datetime.now()\n",
        "end_month = (today.replace(day=1) - timedelta(days=1)).month\n",
        "end_year = (today.replace(day=1) - timedelta(days=1)).year\n",
        "start_month = end_month - 4 if end_month > 4 else 12 + (end_month - 4)\n",
        "start_year = end_year if end_month > 4 else end_year - 1\n",
        "\n",
        "# Generate new file names for 2025\n",
        "def get_new_file_names(year, start_month):\n",
        "    files = []\n",
        "    for i in range(5):\n",
        "        month = (start_month + i - 1) % 12 + 1\n",
        "        y = year if start_month + i <= 12 else year + 1\n",
        "        files.append(f\"data/{y:04d}-{month:02d}_1H_zone.csv\")\n",
        "    return files\n",
        "\n",
        "NEW_ZONE_FILES = get_new_file_names(end_year, start_month)\n",
        "NEW_WEATHER_FILE = 'data/weather_2025.csv'\n",
        "\n",
        "# --- Synthesize Zone Data ---\n",
        "for orig, new, m in zip(ORIG_ZONE_FILES, NEW_ZONE_FILES, range(start_month, start_month+5)):\n",
        "    df = pd.read_csv(orig)\n",
        "    # Shift PUTime to new year/month, preserve hour/min/sec\n",
        "    first_old = pd.to_datetime(df['PUTime'].iloc[0])\n",
        "    new_year = end_year if m <= 12 else end_year + 1\n",
        "    new_month = (m-1)%12+1\n",
        "    day_offset = (datetime(new_year, new_month, 1) - datetime(first_old.year, first_old.month, 1)).days\n",
        "    df['PUTime'] = pd.to_datetime(df['PUTime']) + pd.Timedelta(days=day_offset)\n",
        "    df['PUTime'] = df['PUTime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    df.to_csv(new, index=False)\n",
        "    print(f\"Created {new}\")\n",
        "\n",
        "# --- Synthesize Weather Data ---\n",
        "weather = pd.read_csv(ORIG_WEATHER_FILE)\n",
        "weather_days = len(weather)\n",
        "start_date = datetime(end_year if start_month <= 12 else end_year+1, start_month, 1)\n",
        "weather['DATE'] = [(start_date + timedelta(days=i)).strftime('%m/%d/%y') for i in range(weather_days)]\n",
        "weather.to_csv(NEW_WEATHER_FILE, index=False)\n",
        "print(f\"Created {NEW_WEATHER_FILE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing for 2025 Data\n",
        "\n",
        "We will preprocess the newly synthesized 2025 taxi demand and weather datasets using the same logic as in the original notebooks. This includes feature engineering, merging, and handling missing values. The resulting dataframe will be used for model training and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after merge: (264552, 29)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>PUZone</th>\n",
              "      <th>Count</th>\n",
              "      <th>PUTime</th>\n",
              "      <th>date</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "      <th>peak_hour</th>\n",
              "      <th>DATE</th>\n",
              "      <th>AWND</th>\n",
              "      <th>...</th>\n",
              "      <th>WDF5</th>\n",
              "      <th>WSF2</th>\n",
              "      <th>WSF5</th>\n",
              "      <th>WT01</th>\n",
              "      <th>WT02</th>\n",
              "      <th>WT03</th>\n",
              "      <th>WT04</th>\n",
              "      <th>WT05</th>\n",
              "      <th>WT06</th>\n",
              "      <th>WT08</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>5.59</td>\n",
              "      <td>...</td>\n",
              "      <td>310.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>582</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>5.59</td>\n",
              "      <td>...</td>\n",
              "      <td>310.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>292</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>5.59</td>\n",
              "      <td>...</td>\n",
              "      <td>310.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>376</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>5.59</td>\n",
              "      <td>...</td>\n",
              "      <td>310.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-04-01</td>\n",
              "      <td>5.59</td>\n",
              "      <td>...</td>\n",
              "      <td>310.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  PUZone  Count     PUTime        date  hour  weekday  peak_hour  \\\n",
              "0           0       0     91 2025-04-01  2025-04-01     0        1          0   \n",
              "1           1       1    582 2025-04-01  2025-04-01     0        1          0   \n",
              "2           2       2    292 2025-04-01  2025-04-01     0        1          0   \n",
              "3           3       3    376 2025-04-01  2025-04-01     0        1          0   \n",
              "4           4       4     67 2025-04-01  2025-04-01     0        1          0   \n",
              "\n",
              "        DATE  AWND  ...   WDF5  WSF2  WSF5  WT01  WT02  WT03  WT04  WT05  \\\n",
              "0 2025-04-01  5.59  ...  310.0  15.0  23.0   0.0   0.0   0.0   0.0   0.0   \n",
              "1 2025-04-01  5.59  ...  310.0  15.0  23.0   0.0   0.0   0.0   0.0   0.0   \n",
              "2 2025-04-01  5.59  ...  310.0  15.0  23.0   0.0   0.0   0.0   0.0   0.0   \n",
              "3 2025-04-01  5.59  ...  310.0  15.0  23.0   0.0   0.0   0.0   0.0   0.0   \n",
              "4 2025-04-01  5.59  ...  310.0  15.0  23.0   0.0   0.0   0.0   0.0   0.0   \n",
              "\n",
              "   WT06  WT08  \n",
              "0   0.0   1.0  \n",
              "1   0.0   1.0  \n",
              "2   0.0   1.0  \n",
              "3   0.0   1.0  \n",
              "4   0.0   1.0  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "# --- Load and Concatenate 2025 Zone Data ---\n",
        "zone_files = sorted(glob.glob('data/2025-*_1H_zone.csv'))\n",
        "df_list = [pd.read_csv(f) for f in zone_files]\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# --- Feature Engineering ---\n",
        "df['PUTime'] = pd.to_datetime(df['PUTime'])\n",
        "df['date'] = df['PUTime'].dt.date\n",
        "df['hour'] = df['PUTime'].dt.hour\n",
        "df['weekday'] = (df['PUTime'].dt.dayofweek < 5).astype(int)\n",
        "df['peak_hour'] = ((df['hour'] >= 16) & (df['hour'] <= 20)).astype(int) | ((df['weekday'] == 1) & (df['hour'] >= 6) & (df['hour'] <= 10)).astype(int)\n",
        "\n",
        "# --- Load and Merge Weather Data ---\n",
        "weather = pd.read_csv('data/weather_2025.csv')\n",
        "weather['DATE'] = pd.to_datetime(weather['DATE'], format='%m/%d/%y')\n",
        "weather['date'] = weather['DATE'].dt.date\n",
        "\n",
        "# Merge on date\n",
        "merged = df.merge(weather, on='date', how='left')\n",
        "\n",
        "# --- Add Lag Features (previous 24 hours and previous 30 days) ---\n",
        "merged = merged.sort_values(['PUZone', 'PUTime'])\n",
        "for lag in range(1, 25):\n",
        "    merged[f'lag_{lag}'] = merged.groupby('PUZone')['Count'].shift(lag)\n",
        "for day in range(1, 31):\n",
        "    merged[f'lag_{day*24}'] = merged.groupby('PUZone')['Count'].shift(day*24)\n",
        "\n",
        "# --- Handle Missing Values ---\n",
        "merged = merged.fillna(0)\n",
        "\n",
        "# --- Final Data ---\n",
        "print('Shape after merge:', merged.shape)\n",
        "display(merged.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training and Comparison\n",
        "\n",
        "We will now train and compare 7 advanced algorithms for taxi demand forecasting, including boosting and balancing techniques. The models will be evaluated using appropriate metrics, and the best-performing model will be highlighted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flask==3.0.3 (from -r requirements.txt (line 2))\n",
            "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting gunicorn==23.0.0 (from -r requirements.txt (line 3))\n",
            "  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 6)) (2.3.2)\n",
            "Collecting numpy==1.26.4 (from -r requirements.txt (line 7))\n",
            "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): still running...\n",
            "  Preparing metadata (pyproject.toml): still running...\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting scikit-learn==1.6.1 (from -r requirements.txt (line 10))\n",
            "  Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
            "Collecting joblib==1.4.2 (from -r requirements.txt (line 11))\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: xgboost==2.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 12)) (2.1.1)\n",
            "Requirement already satisfied: lightgbm==4.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 13)) (4.3.0)\n",
            "Collecting catboost==1.2.5 (from -r requirements.txt (line 14))\n",
            "  Using cached catboost-1.2.5.tar.gz (69.6 MB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: still running...\n",
            "  Installing build dependencies: finished with status 'error'\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × pip subprocess to install build dependencies did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [157 lines of output]\n",
            "      Collecting setuptools>=64.0\n",
            "        Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "      Collecting wheel\n",
            "        Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "      Collecting jupyterlab==3.*,>=3.0.6\n",
            "        Using cached jupyterlab-3.6.8-py3-none-any.whl.metadata (12 kB)\n",
            "      Collecting conan~=1.62\n",
            "        Using cached conan-1.66.0.tar.gz (789 kB)\n",
            "        Installing build dependencies: started\n",
            "        Installing build dependencies: finished with status 'done'\n",
            "        Getting requirements to build wheel: started\n",
            "        Getting requirements to build wheel: finished with status 'done'\n",
            "        Preparing metadata (pyproject.toml): started\n",
            "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "      Collecting ipython (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached ipython-9.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "      Collecting packaging (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "      Collecting tornado>=6.1.0 (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached tornado-6.5.2-cp39-abi3-win_amd64.whl.metadata (2.9 kB)\n",
            "      Collecting jupyter-core (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached jupyter_core-5.8.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "      Collecting jupyterlab-server~=2.19 (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "      Collecting jupyter-server<3,>=1.16.0 (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "      Collecting jupyter-ydoc~=0.2.4 (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached jupyter_ydoc-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "      Collecting jupyter-server-ydoc~=0.8.0 (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached jupyter_server_ydoc-0.8.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "      Collecting nbclassic (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached nbclassic-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "      Collecting notebook<7 (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached notebook-6.5.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "      Collecting jinja2>=2.1 (from jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "      Collecting requests<3.0.0,>=2.25 (from conan~=1.62)\n",
            "        Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "      Collecting urllib3<1.27,>=1.26.6 (from conan~=1.62)\n",
            "        Using cached urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "      Collecting colorama<0.5.0,>=0.3.3 (from conan~=1.62)\n",
            "        Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "      Collecting PyYAML<6.1,>=3.11 (from conan~=1.62)\n",
            "        Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
            "      Collecting patch-ng<1.18,>=1.17.4 (from conan~=1.62)\n",
            "        Using cached patch-ng-1.17.4.tar.gz (17 kB)\n",
            "        Installing build dependencies: started\n",
            "        Installing build dependencies: finished with status 'done'\n",
            "        Getting requirements to build wheel: started\n",
            "        Getting requirements to build wheel: finished with status 'done'\n",
            "        Preparing metadata (pyproject.toml): started\n",
            "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "      Collecting fasteners>=0.14.1 (from conan~=1.62)\n",
            "        Using cached fasteners-0.20-py3-none-any.whl.metadata (4.8 kB)\n",
            "      Collecting six<=1.16.0,>=1.10.0 (from conan~=1.62)\n",
            "        Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "      Collecting node-semver==0.6.1 (from conan~=1.62)\n",
            "        Using cached node_semver-0.6.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "      Collecting pygments<3.0,>=2.0 (from conan~=1.62)\n",
            "        Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "      Collecting tqdm<5,>=4.28.1 (from conan~=1.62)\n",
            "        Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "      Collecting python-dateutil<3,>=2.7.0 (from conan~=1.62)\n",
            "        Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "      Collecting bottle<0.13,>=0.12.8 (from conan~=1.62)\n",
            "        Using cached bottle-0.12.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "      Collecting pluginbase>=0.5 (from conan~=1.62)\n",
            "        Using cached pluginbase-1.0.1.tar.gz (43 kB)\n",
            "        Installing build dependencies: started\n",
            "        Installing build dependencies: finished with status 'done'\n",
            "        Getting requirements to build wheel: started\n",
            "        Getting requirements to build wheel: finished with status 'done'\n",
            "        Preparing metadata (pyproject.toml): started\n",
            "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "      Collecting PyJWT<3.0.0,>=2.4.0 (from conan~=1.62)\n",
            "        Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "      Collecting MarkupSafe>=2.0 (from jinja2>=2.1->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
            "      Collecting anyio>=3.1.0 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "      Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "      Collecting jupyter-client>=7.4.4 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "      Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "      Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "      Collecting nbconvert>=6.4.4 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
            "      Collecting nbformat>=5.3.0 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "      Collecting prometheus-client>=0.9 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "      Collecting pywinpty>=2.0.1 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached pywinpty-3.0.0-cp313-cp313-win_amd64.whl.metadata (101 bytes)\n",
            "      Collecting pyzmq>=24 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached pyzmq-27.1.0-cp312-abi3-win_amd64.whl.metadata (6.0 kB)\n",
            "      Collecting send2trash>=1.8.2 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "      Collecting terminado>=0.8.3 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "      Collecting traitlets>=5.6.0 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "      Collecting websocket-client>=1.7 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "      Collecting jupyter-server-fileid<1,>=0.6.0 (from jupyter-server-ydoc~=0.8.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached jupyter_server_fileid-0.9.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "      Collecting ypy-websocket<0.9.0,>=0.8.2 (from jupyter-server-ydoc~=0.8.0->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached ypy_websocket-0.8.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "      Collecting y-py<0.7.0,>=0.6.0 (from jupyter-ydoc~=0.2.4->jupyterlab==3.*,>=3.0.6)\n",
            "        Using cached y_py-0.6.2.tar.gz (53 kB)\n",
            "        Installing build dependencies: started\n",
            "        Installing build dependencies: finished with status 'done'\n",
            "        Getting requirements to build wheel: started\n",
            "        Getting requirements to build wheel: finished with status 'done'\n",
            "        Installing backend dependencies: started\n",
            "        Installing backend dependencies: finished with status 'done'\n",
            "        Preparing metadata (pyproject.toml): started\n",
            "        Preparing metadata (pyproject.toml): finished with status 'error'\n",
            "        error: subprocess-exited-with-error\n",
            "      \n",
            "        Ã— Preparing metadata (pyproject.toml) did not run successfully.\n",
            "        â”‚ exit code: 1\n",
            "        â•°â”€> [22 lines of output]\n",
            "            Checking for Rust toolchain....\n",
            "            Rust not found, installing into a temporary directory\n",
            "            Python reports SOABI: cp313-win_amd64\n",
            "            Computed rustc target triple: x86_64-pc-windows-msvc\n",
            "            Installation directory: C:\\Users\\hp\\AppData\\Local\\puccinialin\\puccinialin\\Cache\n",
            "            Rustup already downloaded\n",
            "            Installing rust to C:\\Users\\hp\\AppData\\Local\\puccinialin\\puccinialin\\Cache\\rustup\n",
            "            warn: It looks like you have an existing rustup settings file at:\n",
            "            warn: C:\\Users\\hp\\.rustup\\settings.toml\n",
            "            warn: Rustup will install the default toolchain as specified in the settings file,\n",
            "            warn: instead of the one inferred from the default host triple.\n",
            "            info: profile set to 'minimal'\n",
            "            info: default host triple is x86_64-pc-windows-msvc\n",
            "            warn: Updating existing toolchain, profile choice will be ignored\n",
            "            info: syncing channel updates for 'stable-x86_64-pc-windows-msvc'\n",
            "            info: default toolchain set to 'stable-x86_64-pc-windows-msvc'\n",
            "            Checking if cargo is installed\n",
            "      \n",
            "            Cargo, the Rust package manager, is not installed or is not on PATH.\n",
            "            This package requires Rust and Cargo to compile extensions. Install it through\n",
            "            the system's package manager or via https://rustup.rs/\n",
            "      \n",
            "            [end of output]\n",
            "      \n",
            "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "      error: metadata-generation-failed\n",
            "      \n",
            "      Ã— Encountered error while generating package metadata.\n",
            "      â•°â”€> See above for output.\n",
            "      \n",
            "      note: This is an issue with the package mentioned above, not pip.\n",
            "      hint: See above for details.\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× pip subprocess to install build dependencies did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from catboost) (3.10.6)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from catboost) (2.3.2)\n",
            "Requirement already satisfied: pandas>=0.24 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from catboost) (2.3.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from catboost) (6.3.0)\n",
            "Requirement already satisfied: six in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->catboost) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->catboost) (1.4.10rc0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly->catboost) (2.4.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install catboost --pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm==4.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from lightgbm==4.3.0) (2.3.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from lightgbm==4.3.0) (1.16.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install lightgbm==4.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost==2.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost==2.1.1) (2.3.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost==2.1.1) (1.16.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install xgboost==2.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CatBoost: 1.2.8\n",
            "LightGBM: 4.3.0\n",
            "XGBoost: 2.1.1\n"
          ]
        }
      ],
      "source": [
        "import catboost\n",
        "import lightgbm\n",
        "import xgboost\n",
        "import sklearn\n",
        "print(\"CatBoost:\", catboost.__version__)\n",
        "print(\"LightGBM:\", lightgbm.__version__)\n",
        "print(\"XGBoost:\", xgboost.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (2.3.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (1.7.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.3.2)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.3.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (3.10.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.10rc0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.3.2)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.3.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (3.10.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.10rc0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-09-09 15:41:49,050] A new study created in memory with name: no-name-13339e3e-49c0-414b-8280-6d2710e811ec\n",
            "  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [1:56:30<95:09:08, 6990.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[W 2025-09-09 17:38:19,817] Trial 0 failed with parameters: {'rf_n_estimators': 368, 'rf_max_depth': 18, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 1, 'xgb_n_estimators': 447, 'xgb_max_depth': 5, 'xgb_lr': 0.022651948347789407, 'lgb_n_estimators': 115, 'lgb_max_depth': 5, 'lgb_lr': 0.01424300965243176, 'cat_n_estimators': 465, 'cat_depth': 10, 'cat_lr': 0.027097389660999952} because of the following error: The value nan is not acceptable.\n",
            "[W 2025-09-09 17:38:19,828] Trial 0 failed with value np.float64(nan).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        }
      ],
      "source": [
        "# --- Imports ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "\n",
        "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Feature Engineering ---\n",
        "def add_time_features(df):\n",
        "    if 'PUTime' in df.columns:\n",
        "        df['PUTime'] = pd.to_datetime(df['PUTime'])\n",
        "        df['hour'] = df['PUTime'].dt.hour\n",
        "        df['day_of_week'] = df['PUTime'].dt.dayofweek\n",
        "        df['month'] = df['PUTime'].dt.month\n",
        "    return df\n",
        "\n",
        "def add_lag_features(df, target, lags=[1,2,3]):\n",
        "    for lag in lags:\n",
        "        df[f\"{target}_lag_{lag}\"] = df[target].shift(lag)\n",
        "    df = df.fillna(method='bfill')\n",
        "    return df\n",
        "\n",
        "merged = add_time_features(merged)\n",
        "merged = add_lag_features(merged, target='Count', lags=[1,2,3])\n",
        "\n",
        "# --- Features & Target ---\n",
        "target = \"Count\"\n",
        "features = [col for col in merged.columns if col not in [\"PUZone\", \"PUTime\", \"Count\", \"date\", \"DATE\"]]\n",
        "\n",
        "X = merged[features]\n",
        "y = merged[target]\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# --- Objective for Optuna ---\n",
        "def objective(trial):\n",
        "    # Hyperparameters\n",
        "    rf_params = {\n",
        "        'n_estimators': trial.suggest_int('rf_n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('rf_max_depth', 10, 30),\n",
        "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 5),\n",
        "        'random_state': 42\n",
        "    }\n",
        "    xgb_params = {\n",
        "        'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('xgb_lr', 0.01, 0.3, log=True),\n",
        "        'objective': 'reg:squarederror',\n",
        "        'random_state': 42\n",
        "    }\n",
        "    lgb_params = {\n",
        "        'n_estimators': trial.suggest_int('lgb_n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('lgb_max_depth', 5, 20),\n",
        "        'learning_rate': trial.suggest_float('lgb_lr', 0.01, 0.3, log=True),\n",
        "        'random_state': 42\n",
        "    }\n",
        "    cat_params = {\n",
        "        'n_estimators': trial.suggest_int('cat_n_estimators', 100, 500),\n",
        "        'depth': trial.suggest_int('cat_depth', 4, 10),\n",
        "        'learning_rate': trial.suggest_float('cat_lr', 0.01, 0.3, log=True),\n",
        "        'verbose': 0,\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    # --- Wrap regressors ---\n",
        "    rf = RandomForestRegressor(**rf_params)\n",
        "    xgb = TransformedTargetRegressor(regressor=XGBRegressor(**xgb_params))\n",
        "    lgbm = TransformedTargetRegressor(regressor=LGBMRegressor(**lgb_params))\n",
        "    cat = TransformedTargetRegressor(regressor=CatBoostRegressor(**cat_params))\n",
        "\n",
        "    # --- Stacking ---\n",
        "    stack_model = StackingRegressor(\n",
        "        estimators=[('rf', rf), ('xgb', xgb), ('lgbm', lgbm), ('cat', cat)],\n",
        "        final_estimator=GradientBoostingRegressor(n_estimators=200, random_state=42),\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', stack_model)\n",
        "    ])\n",
        "\n",
        "    cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
        "    r2 = cross_val_score(pipeline, X, y, cv=cv, scoring='r2', n_jobs=1)\n",
        "    return r2.mean()\n",
        "\n",
        "# --- Run Optuna ---\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "print(\"Best R²:\", study.best_value)\n",
        "print(\"Best Hyperparameters:\", study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sparse\n",
            "  Downloading sparse-0.17.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sparse) (2.3.2)\n",
            "Collecting numba>=0.49 (from sparse)\n",
            "  Downloading numba-0.61.2-cp313-cp313-win_amd64.whl.metadata (2.8 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.49->sparse)\n",
            "  Downloading llvmlite-0.44.0-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting numpy>=1.17 (from sparse)\n",
            "  Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
            "Downloading sparse-0.17.0-py2.py3-none-any.whl (259 kB)\n",
            "Downloading numba-0.61.2-cp313-cp313-win_amd64.whl (2.8 MB)\n",
            "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.8/2.8 MB 15.7 MB/s  0:00:00\n",
            "Downloading llvmlite-0.44.0-cp313-cp313-win_amd64.whl (30.3 MB)\n",
            "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 1.6/30.3 MB 8.5 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 2.6/30.3 MB 6.5 MB/s eta 0:00:05\n",
            "   ---- ----------------------------------- 3.1/30.3 MB 5.8 MB/s eta 0:00:05\n",
            "   ---- ----------------------------------- 3.4/30.3 MB 4.7 MB/s eta 0:00:06\n",
            "   ---- ----------------------------------- 3.7/30.3 MB 3.7 MB/s eta 0:00:08\n",
            "   ----- ---------------------------------- 4.2/30.3 MB 3.2 MB/s eta 0:00:09\n",
            "   ------ --------------------------------- 4.7/30.3 MB 3.1 MB/s eta 0:00:09\n",
            "   ------ --------------------------------- 5.2/30.3 MB 3.1 MB/s eta 0:00:09\n",
            "   ------- -------------------------------- 6.0/30.3 MB 3.1 MB/s eta 0:00:08\n",
            "   --------- ------------------------------ 7.1/30.3 MB 3.3 MB/s eta 0:00:08\n",
            "   ---------- ----------------------------- 8.1/30.3 MB 3.5 MB/s eta 0:00:07\n",
            "   ------------ --------------------------- 9.2/30.3 MB 3.6 MB/s eta 0:00:06\n",
            "   ------------- -------------------------- 10.2/30.3 MB 3.7 MB/s eta 0:00:06\n",
            "   -------------- ------------------------- 11.0/30.3 MB 3.7 MB/s eta 0:00:06\n",
            "   ---------------- ----------------------- 12.6/30.3 MB 3.9 MB/s eta 0:00:05\n",
            "   ------------------- -------------------- 14.4/30.3 MB 4.2 MB/s eta 0:00:04\n",
            "   --------------------- ------------------ 16.0/30.3 MB 4.5 MB/s eta 0:00:04\n",
            "   ----------------------- ---------------- 17.8/30.3 MB 4.7 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 18.6/30.3 MB 4.6 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 18.9/30.3 MB 4.5 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 19.4/30.3 MB 4.4 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 19.9/30.3 MB 4.3 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 20.4/30.3 MB 4.3 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 21.5/30.3 MB 4.3 MB/s eta 0:00:03\n",
            "   ----------------------------- ---------- 22.5/30.3 MB 4.3 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 23.9/30.3 MB 4.3 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 24.6/30.3 MB 4.3 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 25.7/30.3 MB 4.4 MB/s eta 0:00:02\n",
            "   ----------------------------------- ---- 27.0/30.3 MB 4.4 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 28.3/30.3 MB 4.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  29.6/30.3 MB 4.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 30.3/30.3 MB 4.5 MB/s  0:00:06\n",
            "Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)\n",
            "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 1.6/12.6 MB 8.1 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 3.1/12.6 MB 8.0 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 3.7/12.6 MB 6.4 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 4.5/12.6 MB 5.5 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 5.5/12.6 MB 5.2 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 6.3/12.6 MB 5.1 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 7.1/12.6 MB 4.9 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 8.1/12.6 MB 4.8 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 9.2/12.6 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 10.7/12.6 MB 5.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.3/12.6 MB 5.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.6/12.6 MB 5.2 MB/s  0:00:02\n",
            "Installing collected packages: numpy, llvmlite, numba, sparse\n",
            "\n",
            "  Attempting uninstall: numpy\n",
            "\n",
            "    Found existing installation: numpy 2.3.2\n",
            "\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "    Uninstalling numpy-2.3.2:\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "      Successfully uninstalled numpy-2.3.2\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------------------------------------- 0/4 [numpy]\n",
            "   ---------- ----------------------------- 1/4 [llvmlite]\n",
            "   ---------- ----------------------------- 1/4 [llvmlite]\n",
            "   ---------- ----------------------------- 1/4 [llvmlite]\n",
            "   ---------- ----------------------------- 1/4 [llvmlite]\n",
            "   ---------- ----------------------------- 1/4 [llvmlite]\n",
            "   ---------- ----------------------------- 1/4 [llvmlite]\n",
            "   ---------- ----------------------------- 1/4 [llvmlite]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   -------------------- ------------------- 2/4 [numba]\n",
            "   ------------------------------ --------- 3/4 [sparse]\n",
            "   ------------------------------ --------- 3/4 [sparse]\n",
            "   ------------------------------ --------- 3/4 [sparse]\n",
            "   ------------------------------ --------- 3/4 [sparse]\n",
            "   ------------------------------ --------- 3/4 [sparse]\n",
            "   ------------------------------ --------- 3/4 [sparse]\n",
            "   ------------------------------ --------- 3/4 [sparse]\n",
            "   ------------------------------ --------- 3/4 [sparse]\n",
            "   ---------------------------------------- 4/4 [sparse]\n",
            "\n",
            "Successfully installed llvmlite-0.44.0 numba-0.61.2 numpy-2.2.6 sparse-0.17.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\~umpy.libs'.\n",
            "  You can safely remove it manually.\n",
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\~umpy'.\n",
            "  You can safely remove it manually.\n"
          ]
        }
      ],
      "source": [
        "!pip install sparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Expanding to 11 Algorithms & Hybrid Models (Including LSTM)\n",
        "\n",
        "We will now expand our comparison to 11 top algorithms, including deep learning (LSTM) and hybrid ensemble models. This will provide a comprehensive benchmark and highlight the best approaches for taxi demand forecasting in 2025.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import StackingRegressor, VotingRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# --- Add more models ---\n",
        "models.update({\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'SVR': SVR(),\n",
        "})\n",
        "\n",
        "# --- LSTM Preparation ---\n",
        "lstm_features = features.copy()\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X[lstm_features])\n",
        "\n",
        "def create_lstm_dataset(X, y, time_steps=24):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        ys.append(y.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_lstm, y_lstm = create_lstm_dataset(X_scaled, y, time_steps=24)\n",
        "X_lstm_train, X_lstm_val = X_lstm[:int(0.8*len(X_lstm))], X_lstm[int(0.8*len(X_lstm)):]\n",
        "y_lstm_train, y_lstm_val = y_lstm[:int(0.8*len(y_lstm))], y_lstm[int(0.8*len(y_lstm)) :]\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, input_shape=(X_lstm_train.shape[1], X_lstm_train.shape[2]), return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='mae')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history = lstm_model.fit(X_lstm_train, y_lstm_train, epochs=30, batch_size=128, validation_data=(X_lstm_val, y_lstm_val), callbacks=[es], verbose=1)\n",
        "lstm_preds = lstm_model.predict(X_lstm_val).flatten()\n",
        "lstm_mae = mean_absolute_error(y_lstm_val, lstm_preds)\n",
        "lstm_rmse = mean_squared_error(y_lstm_val, lstm_preds, squared=False)\n",
        "lstm_r2 = r2_score(y_lstm_val, lstm_preds)\n",
        "results['LSTM'] = {'MAE': lstm_mae, 'RMSE': lstm_rmse, 'R2': lstm_r2}\n",
        "print(f\"LSTM: MAE={lstm_mae:.2f}, RMSE={lstm_rmse:.2f}, R2={lstm_r2:.2f}\")\n",
        "\n",
        "# --- Hybrid Models ---\n",
        "# Stacking (using top 3 models)\n",
        "top3 = list(results_df.index[:3])\n",
        "stacking = StackingRegressor([\n",
        "    (name, models[name]) for name in top3 if name in models\n",
        "], final_estimator=LinearRegression())\n",
        "stacking.fit(X_train, y_train)\n",
        "stacking_preds = stacking.predict(X_val)\n",
        "stacking_mae = mean_absolute_error(y_val, stacking_preds)\n",
        "stacking_rmse = mean_squared_error(y_val, stacking_preds, squared=False)\n",
        "stacking_r2 = r2_score(y_val, stacking_preds)\n",
        "results['Stacking'] = {'MAE': stacking_mae, 'RMSE': stacking_rmse, 'R2': stacking_r2}\n",
        "print(f\"Stacking: MAE={stacking_mae:.2f}, RMSE={stacking_rmse:.2f}, R2={stacking_r2:.2f}\")\n",
        "\n",
        "# Voting Ensemble (all models)\n",
        "voting = VotingRegressor([(name, model) for name, model in models.items()])\n",
        "voting.fit(X_train, y_train)\n",
        "voting_preds = voting.predict(X_val)\n",
        "voting_mae = mean_absolute_error(y_val, voting_preds)\n",
        "voting_rmse = mean_squared_error(y_val, voting_preds, squared=False)\n",
        "voting_r2 = r2_score(y_val, voting_preds)\n",
        "results['Voting'] = {'MAE': voting_mae, 'RMSE': voting_rmse, 'R2': voting_r2}\n",
        "print(f\"Voting: MAE={voting_mae:.2f}, RMSE={voting_rmse:.2f}, R2={voting_r2:.2f}\")\n",
        "\n",
        "# --- Update Results DataFrame and Plot ---\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df = results_df.sort_values('MAE')\n",
        "display(results_df)\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=results_df.index, y=results_df['MAE'])\n",
        "plt.title('Model MAE Comparison (11+ Models)')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
